{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import six\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_DIR = './data/VOCdevkit/VOC2012/ImageSets/Segmentation'\n",
    "OUTPUT_DIR = \"./data/VOCdevkit/tfrecord\"\n",
    "\n",
    "IMAGE_DIR = './data/VOCdevkit/VOC2012/JPEGImages'\n",
    "IMAGE_FORMAT = 'jpg'\n",
    "\n",
    "SEGMENTATION_DIR = \"./data/VOCdevkit/VOC2012/SegmentationClass\"\n",
    "SEGMENTATION_FORMAT = 'png'\n",
    "\n",
    "NUM_SHARDS = 6\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def img_seg_to_example(filename, image_data, seg_data):\n",
    "    image_shape = tf.image.decode_jpeg(image_data).shape\n",
    "    \n",
    "    feature = {\n",
    "        'image/encoded': _bytes_feature(image_data),\n",
    "        'image/height': _int64_feature(image_shape[0]),\n",
    "        'image/width': _int64_feature(image_shape[1]),\n",
    "        'image/channels':  _int64_feature(image_shape[2]),\n",
    "        'image/segmentation/class/encoded': (_bytes_feature(seg_data))\n",
    "    }\n",
    "    \n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "def convert_dataset(dataset_split):\n",
    "    dataset = os.path.basename(dataset_split)[:-4]\n",
    "    \n",
    "    filenames = [x.strip('\\n') for x in open(dataset_split, 'r')]\n",
    "    num_images = len(filenames)\n",
    "    \n",
    "    print(f\"Processing {dataset}: {num_images} Images\")\n",
    "    num_per_shard = int(math.ceil(num_images / NUM_SHARDS))\n",
    "    \n",
    "    for shard_id in range(NUM_SHARDS):\n",
    "        output_filename = os.path.join(OUTPUT_DIR, '%s-%05d-of-%05d.tfrecord' % (dataset, shard_id, NUM_SHARDS))\n",
    "        \n",
    "        with tf.io.TFRecordWriter(output_filename) as writer:\n",
    "            start_idx = shard_id * num_per_shard\n",
    "            end_idx = min((shard_id + 1) * num_per_shard, num_images)\n",
    "            \n",
    "            for i in range(start_idx, end_idx):\n",
    "                # READ IMAGE  \n",
    "                image_filename = os.path.join(IMAGE_DIR, filenames[i] + '.' + IMAGE_FORMAT)\n",
    "                image_data = tf.io.gfile.GFile(image_filename, 'rb').read()\n",
    "\n",
    "                # READ SEGMENTATION\n",
    "                seg_filename = os.path.join(SEGMENTATION_DIR, filenames[i] + '.' + SEGMENTATION_FORMAT)\n",
    "                seg_data = tf.io.gfile.GFile(seg_filename, mode='rb').read()\n",
    "                \n",
    "                # CREATE TFRECORD EXAMPLE\n",
    "                example = img_seg_to_example(filenames[i], image_data, seg_data)\n",
    "\n",
    "                # WRITE TO DISK\n",
    "                writer.write(example.SerializeToString())\n",
    "            \n",
    "def main():\n",
    "    dataset_splits = tf.io.gfile.glob(os.path.join(LIST_DIR, \"*.txt\"))\n",
    "    for dataset_split in dataset_splits:\n",
    "        convert_dataset(dataset_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train: 1464 Images\n",
      "Processing val: 1449 Images\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIM = 256\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 500\n",
    "\n",
    "def parse_image(content, channels):\n",
    "    return tf.cond(\n",
    "        tf.image.is_jpeg(content), \n",
    "        lambda: tf.image.decode_jpeg(content, channels), \n",
    "        lambda: tf.image.decode_png(content, channels)\n",
    "    )\n",
    "    \n",
    "def parse_dataset(example_proto):\n",
    "    features = {\n",
    "        'image/encoded':\n",
    "            tf.io.FixedLenFeature((), tf.string, default_value=''),\n",
    "        'image/height':\n",
    "            tf.io.FixedLenFeature((), tf.int64, default_value=0),\n",
    "        'image/width':\n",
    "            tf.io.FixedLenFeature((), tf.int64, default_value=0),\n",
    "        'image/segmentation/class/encoded':\n",
    "            tf.io.FixedLenFeature((), tf.string, default_value=''),\n",
    "    }\n",
    "    \n",
    "    parsed_feature = tf.io.parse_single_example(example_proto, features)\n",
    "    \n",
    "    image = parse_image(parsed_feature['image/encoded'], channels=3)\n",
    "    image = tf.image.resize(image, (IMG_DIM, IMG_DIM))\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    \n",
    "    label = parse_image(parsed_feature['image/segmentation/class/encoded'], channels=1)\n",
    "    label = tf.image.resize(label, (IMG_DIM, IMG_DIM))\n",
    "    label = tf.image.convert_image_dtype(label, tf.int64)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "train_list_ds = tf.data.Dataset.list_files(OUTPUT_DIR + \"/train-*.tfrecord\")\n",
    "valid_list_ds = tf.data.Dataset.list_files(OUTPUT_DIR + \"/val-*.tfrecord\")\n",
    "\n",
    "\n",
    "train_ds = (tf.data\n",
    "    .TFRecordDataset(train_list_ds)\n",
    "    .map(parse_dataset, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "valid_ds = (tf.data\n",
    "    .TFRecordDataset(valid_list_ds)\n",
    "    .map(parse_dataset, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core._api.v2.image' has no attribute 'resize_bilinear'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5847a03bffa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-5847a03bffa6>\u001b[0m in \u001b[0;36mbuild_network\u001b[0;34m(input_shape, nclasses, use_ctx)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'ctx_output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbilinear_upsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear_upsample'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m    793\u001b[0m       \u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-5847a03bffa6>\u001b[0m in \u001b[0;36mbilinear_upsample\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbilinear_upsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mupsampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_bilinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupsampled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_core._api.v2.image' has no attribute 'resize_bilinear'"
     ]
    }
   ],
   "source": [
    "def conv_block(layer_size, input_data, filters, kernel_size = 3, dilation_rate=1, padding = 'same', pool = False, name = ''):\n",
    "    if dilation_rate == 1:\n",
    "        conv_type = 'conv'\n",
    "    else:\n",
    "        conv_type = 'dilated_conv'\n",
    "    \n",
    "    for i in range(1, layer_size + 1):\n",
    "        input_data = (keras.layers.Conv2D(\n",
    "                filters=filters, \n",
    "                kernel_size=kernel_size, \n",
    "                dilation_rate=dilation_rate,\n",
    "                padding=padding,\n",
    "                name=f'block_{conv_type}_{name}_{i}', \n",
    "                use_bias=True))(input_data)\n",
    "        input_data = keras.layers.Activation('relu', name=f'relu_{name}_{i}')(input_data)\n",
    "        \n",
    "    if pool:\n",
    "        input_data = keras.layers.MaxPool2D(2, name=f'max_pool_{name}')(input_data)\n",
    "    \n",
    "    return input_data\n",
    "  \n",
    "def bilinear_upsample(sample):\n",
    "    image_size = sample[1]\n",
    "    upsampled = tf.image.resize(sample[0], )\n",
    "    return upsampled\n",
    "    \n",
    "def build_network(input_shape, nclasses, use_ctx = False):\n",
    "    inputs = keras.layers.Input(input_shape)\n",
    "    x = conv_block(layer_size=2, input_data=inputs, kernel_size=3, filters=64, pool=True, name=1)\n",
    "    x = conv_block(layer_size=2, input_data=x, kernel_size=3, filters=128, pool=True, name=2)\n",
    "    x = conv_block(layer_size=3, input_data=x, kernel_size=3, filters=256, pool=True, name=3)\n",
    "    x = conv_block(layer_size=3, input_data=x, kernel_size=3, filters=512, pool=False, name=4)\n",
    "    x = conv_block(layer_size=3, input_data=x, kernel_size=3, filters=512, dilation_rate=2, pool=False, name=5)\n",
    "    \n",
    "    x = conv_block(layer_size=1, input_data=x, kernel_size=7, filters=4096, dilation_rate=4, name='_FCN1')\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    x = conv_block(layer_size=1, input_data=x, kernel_size=7, filters=4096, name='_FCN2')\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    \n",
    "    if use_ctx:\n",
    "        x = conv_block(layer_size=2, input_data=x, filters=128, kernel_size=3, name='_ctx1')\n",
    "        x = conv_block(layer_size=1, input_data=x, filters=256, kernel_size=3, name='_ctx2', dilation_rate=2)\n",
    "        x = conv_block(layer_size=1, input_data=x, filters=512, kernel_size=3, name='_ctx3', dilation_rate=4)\n",
    "        x = conv_block(layer_size=1, input_data=x, filters=1024, kernel_size=3, name='_ctx4', dilation_rate=8)\n",
    "        x = conv_block(layer_size=1, input_data=x, filters=2048, kernel_size=3, name='_ctx5', dilation_rate=16)\n",
    "        x = conv_block(layer_size=1, input_data=x, filters=2048, kernel_size=3, name='_ctx6')\n",
    "        x = keras.layers.Conv2D(filters=nclasses, kernel_size=1, padding='same', name=f'ctx_output')(x)\n",
    "    \n",
    "    x = keras.layers.Lambda(bilinear_upsample, name='bilinear_upsample')([x, input_shape])\n",
    "    x = keras.layers.Softmax()(x)\n",
    "    \n",
    "    return keras.Model(inputs, x)\n",
    "    \n",
    "model = build_network((IMG_DIM, IMG_DIM, 3), 21, True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
