{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSPNET with tf2.0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPso2t1Pr0hLR8qjyn+ICgg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SatioO/DL_Practices/blob/master/PSPNET_with_tf2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUq4zJzj7tzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.layers as layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANCiz1q-kZ6K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "ddd1b17e-0bb2-42ec-dc29-1ab8d2971610"
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Launch pad/tfrecord.zip\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Launch pad/tfrecord.zip\n",
            "replace tfrecord/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: tfrecord/.DS_Store      \n",
            "  inflating: __MACOSX/tfrecord/._.DS_Store  \n",
            "  inflating: tfrecord/train-00002-of-00004.tfrecord  \n",
            "  inflating: tfrecord/val-00002-of-00004.tfrecord  \n",
            "  inflating: tfrecord/train-00003-of-00004.tfrecord  \n",
            "  inflating: tfrecord/val-00003-of-00004.tfrecord  \n",
            "  inflating: tfrecord/train-00000-of-00004.tfrecord  \n",
            "  inflating: tfrecord/val-00000-of-00004.tfrecord  \n",
            "  inflating: tfrecord/train-00001-of-00004.tfrecord  \n",
            "  inflating: tfrecord/val-00001-of-00004.tfrecord  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugIjuIT6k4Kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_DIM = 256\n",
        "BATCH_SIZE = 32\n",
        "N_CLASSES = 64\n",
        "OUTPUT_CHANNELS = 21\n",
        "OUTPUT_DIR = \"/content/tfrecord\"\n",
        "\n",
        "def normalize(input_image, input_mask):\n",
        "    return input_image, input_mask\n",
        "    \n",
        "def parse_dataset(example_proto):\n",
        "    features = {\n",
        "        'image/encoded':\n",
        "            tf.io.FixedLenFeature((), tf.string, default_value=''),\n",
        "        'image/height':\n",
        "            tf.io.FixedLenFeature((), tf.int64, default_value=0),\n",
        "        'image/width':\n",
        "            tf.io.FixedLenFeature((), tf.int64, default_value=0),\n",
        "        'image/segmentation':\n",
        "            tf.io.FixedLenFeature((), tf.string, default_value=''),\n",
        "    }\n",
        "    \n",
        "    parsed_feature = tf.io.parse_single_example(example_proto, features)\n",
        "    \n",
        "    image = tf.image.decode_jpeg(parsed_feature['image/encoded'], channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, (IMG_DIM, IMG_DIM))\n",
        "    image = tf.image.per_image_standardization(image)\n",
        "    \n",
        "    label = tf.image.decode_png(parsed_feature['image/segmentation'], 1)\n",
        "    label = tf.cast(label, tf.int32)\n",
        "    \n",
        "    return image, label\n",
        "\n",
        "train_list_ds = tf.data.Dataset.list_files(OUTPUT_DIR + \"/train-*.tfrecord\")\n",
        "valid_list_ds = tf.data.Dataset.list_files(OUTPUT_DIR + \"/val-*.tfrecord\")\n",
        "\n",
        "train_ds = (tf.data\n",
        "    .TFRecordDataset(train_list_ds)\n",
        "    .map(parse_dataset, num_parallel_calls=tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "valid_ds = (tf.data\n",
        "    .TFRecordDataset(valid_list_ds)\n",
        "    .map(parse_dataset, num_parallel_calls=tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "train_dataset = train_ds.cache().shuffle(BATCH_SIZE * 50).batch(BATCH_SIZE).repeat()\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "valid_dataset = valid_ds.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54SFqmfFk7ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2), dilation=1):\n",
        "  # A block that has a conv layer at shortcut.\n",
        "  filter1, filter2, filter3 = filters\n",
        "  \n",
        "  conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "  bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "  strides = (1, 1) if dilation > 1 else strides\n",
        "\n",
        "  x = layers.Conv2D(filter1, (1, 1), strides=strides, name=conv_name_base + '2a')(input_tensor)\n",
        "  x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  x = layers.Conv2D(filter2, kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base + '2b', dilation_rate=dilation)(x)\n",
        "  x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  x = layers.Conv2D(filter3, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2c')(x)\n",
        "  x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n",
        "\n",
        "  shortcut = layers.Conv2D(filter3, (1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base + '1')(input_tensor)\n",
        "  shortcut = layers.BatchNormalization(name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "  x = layers.add([x, shortcut])\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block, dilation=1):\n",
        "  # The identity block is the block that has no conv layer at shortcut.\n",
        "  filter1, filter2, filter3 = filters\n",
        "\n",
        "  conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "  bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "  x = layers.Conv2D(filter1, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2a')(input_tensor)\n",
        "  x = layers.BatchNormalization(name=bn_name_base + '2a')(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  x = layers.Conv2D(filter2, kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base + '2b', dilation_rate=dilation)(x)\n",
        "  x = layers.BatchNormalization(name=bn_name_base + '2b')(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  x = layers.Conv2D(filter3, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2c')(x)\n",
        "  x = layers.BatchNormalization(name=bn_name_base + '2c')(x)\n",
        "  x = layers.add([x, input_tensor])\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "\n",
        "def resnet50(img_input):\n",
        "  x = layers.ZeroPadding2D((3, 3), name='conv1_pad')(img_input)\n",
        "  x = layers.Conv2D(64, (7, 7), strides=(2, 2), padding='valid', kernel_initializer='he_normal', name='conv1')(x)\n",
        "  x = layers.BatchNormalization(name='bn_conv1')(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "  x = layers.ZeroPadding2D((1, 1), name='pool1_pad')(x)\n",
        "  x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "  f1 = x\n",
        "\n",
        "  x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "  x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "  x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "  f2 = x\n",
        "\n",
        "  x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "  x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "  x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "  x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "  f3 = x\n",
        "\n",
        "  x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "  x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "  x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "  x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "  x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "  x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "  f4 = x\n",
        "\n",
        "  x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "  x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "  x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "  f5 = x\n",
        "\n",
        "  return [f1, f2, f3, f4, f5]\n",
        "\n",
        "\n",
        "img_input = keras.layers.Input((IMG_DIM, IMG_DIM, 3))\n",
        "model = resnet50(img_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KQffR4kp6kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3T6wVtjqOr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}